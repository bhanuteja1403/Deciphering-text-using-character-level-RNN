{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfn3Yh7oG-QI",
        "outputId": "dffc86e0-bac3-4fea-e9e6-3af672df3bba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 27\n",
            "Epoch 1/10 - Loss: 0.5431\n",
            "Epoch 2/10 - Loss: 0.0092\n",
            "Epoch 3/10 - Loss: 0.0034\n",
            "Epoch 4/10 - Loss: 0.0019\n",
            "Epoch 5/10 - Loss: 0.0012\n",
            "Epoch 6/10 - Loss: 0.0009\n",
            "Epoch 7/10 - Loss: 0.0007\n",
            "Epoch 8/10 - Loss: 0.0005\n",
            "Epoch 9/10 - Loss: 0.0004\n",
            "Epoch 10/10 - Loss: 0.0003\n",
            "Cipher input: wklv prylh zdv juhdw\n",
            "Deciphered output: thistmovietwastgreat\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 1. Caesar cipher function (shift 3 by default)\n",
        "def caesar_encrypt(text, shift=3):\n",
        "    result = \"\"\n",
        "    for char in text:\n",
        "        if char.isalpha():\n",
        "            base = ord('a') if char.islower() else ord('A')\n",
        "            result += chr((ord(char) - base + shift) % 26 + base)\n",
        "        else:\n",
        "            result += char\n",
        "    return result\n",
        "\n",
        "# 2. Load dataset\n",
        "import csv\n",
        "\n",
        "# df = pd.read_csv(\"/content/IMDB Dataset.csv\", engine='python', quoting=csv.QUOTE_ALL)\n",
        "# df = pd.read_csv('/content/IMDB Dataset.csv', quoting=csv.QUOTE_ALL, on_bad_lines='skip')\n",
        "df = pd.read_csv(\n",
        "    '/content/IMDB Dataset.csv',\n",
        "    engine='python',\n",
        "    quoting=csv.QUOTE_MINIMAL,\n",
        "    on_bad_lines='skip'\n",
        ")\n",
        "\n",
        "df = df.drop(columns=['sentiment'])\n",
        "\n",
        "\n",
        "# 3. Remove HTML tags & preprocess text\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'<.*?>', '', text)           # Remove HTML tags\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)        # Keep only letters and spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()    # Replace multiple spaces with one\n",
        "    return text\n",
        "\n",
        "df['clean_review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# 4. Create ciphered version of the cleaned text\n",
        "df['cipher_review'] = df['clean_review'].apply(lambda x: caesar_encrypt(x, shift=3))\n",
        "\n",
        "# 5. Build character vocabulary\n",
        "all_text = ' '.join(df['clean_review'].tolist() + df['cipher_review'].tolist())\n",
        "chars = sorted(list(set(all_text)))\n",
        "char2idx = {c: i for i, c in enumerate(chars)}\n",
        "idx2char = {i: c for i, c in enumerate(chars)}\n",
        "vocab_size = len(chars)\n",
        "print(f'Vocabulary size: {vocab_size}')\n",
        "\n",
        "# 6. Dataset class for cipher/plain pairs\n",
        "class CipherDataset(Dataset):\n",
        "    def __init__(self, cipher_texts, plain_texts, char2idx):\n",
        "        self.cipher_texts = cipher_texts\n",
        "        self.plain_texts = plain_texts\n",
        "        self.char2idx = char2idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cipher_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        cipher_seq = torch.tensor([self.char2idx[c] for c in self.cipher_texts[idx]], dtype=torch.long)\n",
        "        plain_seq = torch.tensor([self.char2idx[c] for c in self.plain_texts[idx]], dtype=torch.long)\n",
        "        return cipher_seq, plain_seq\n",
        "\n",
        "# 7. Collate function for padding variable-length sequences\n",
        "def collate_fn(batch):\n",
        "    cipher_seqs, plain_seqs = zip(*batch)\n",
        "    cipher_seqs_padded = pad_sequence(cipher_seqs, batch_first=True, padding_value=char2idx[' '])\n",
        "    plain_seqs_padded = pad_sequence(plain_seqs, batch_first=True, padding_value=char2idx[' '])\n",
        "    return cipher_seqs_padded, plain_seqs_padded\n",
        "\n",
        "# 8. DataLoader setup\n",
        "dataset = CipherDataset(df['cipher_review'].tolist(), df['clean_review'].tolist(), char2idx)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# 9. Define character-level LSTM model\n",
        "class CharDecoderLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size=128):\n",
        "        super(CharDecoderLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "\n",
        "# 10. Training setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CharDecoderLSTM(vocab_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=char2idx[' '])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 11. Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for cipher_batch, plain_batch in dataloader:\n",
        "        cipher_batch = cipher_batch.to(device)\n",
        "        plain_batch = plain_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(cipher_batch)\n",
        "\n",
        "        outputs = outputs.view(-1, vocab_size)\n",
        "        targets = plain_batch.view(-1)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "# 12. Save the trained model\n",
        "torch.save(model.state_dict(), \"char_decoder_lstm.pth\")\n",
        "\n",
        "def decode_output(output_tensor):\n",
        "    pred_idxs = output_tensor.argmax(dim=2)\n",
        "    texts = []\n",
        "    for seq in pred_idxs:\n",
        "        chars = [idx2char[idx.item()] for idx in seq]\n",
        "        text = ''.join(chars)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "\n",
        "# 14. Function to preprocess new cipher text for inference\n",
        "def preprocess_text(text, char2idx):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    return torch.tensor([char2idx.get(c, char2idx[' ']) for c in text], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "# 15. Function to decipher a new cipher text string\n",
        "def decipher_text(model, cipher_text, char2idx, idx2char, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_seq = preprocess_text(cipher_text, char2idx).to(device)\n",
        "        output, _ = model(input_seq)\n",
        "        decoded = decode_output(output)\n",
        "    return decoded[0]\n",
        "\n",
        "# Example test after training\n",
        "example_plain = \"this movie was great\"\n",
        "example_cipher = caesar_encrypt(example_plain, shift=3)\n",
        "print(\"Cipher input:\", example_cipher)\n",
        "print(\"Deciphered output:\", decipher_text(model, example_cipher, char2idx, idx2char, device))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_accuracy(model, dataloader, char2idx, idx2char, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for cipher_batch, plain_batch in dataloader:\n",
        "            cipher_batch = cipher_batch.to(device)\n",
        "            plain_batch = plain_batch.to(device)\n",
        "\n",
        "            outputs, _ = model(cipher_batch)\n",
        "            pred_indices = outputs.argmax(dim=2)\n",
        "\n",
        "            mask = (plain_batch != char2idx[' '])  # Ignore padding\n",
        "            correct += (pred_indices[mask] == plain_batch[mask]).sum().item()\n",
        "            total += mask.sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Character-level Accuracy: {accuracy:.4f}\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "fI8KhwIGjtZ8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpKBkk18LyU-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gADnGbfhMfs8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}